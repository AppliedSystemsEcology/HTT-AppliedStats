---
title: "HTT_AppliedStats_FinalProject_2025"
format: html
---
```{r}
# via Quarto: Ensure that the code used to generate markdown isn't included in the final output
#| echo: false
```

```{r}
# Load libraries
library(tidyverse)
library(dplyr)
library(purrr)
```

```{r}
# Set working directory in terminal
# setwd( "C:/Users/mykal/OneDrive - The Pennsylvania State University/Grab Lab - Mykalas_Projects - Documents/Mykalas_Projects/projects/High Tunnel Thrips/analysis/HTT-AppliedStats/data")


# Load tomato thrips damage data from local environment
TomatoThripsDamageRS <- read.csv("HTTFruitRating_2025_RS.csv")
TomatoThripsDamageSEAREC <- read.csv("HTTFruitRating_2025_SEAREC.csv")

# Load ground cover ID data from local environment
GroundCoverID <- read.csv("Site_GroundCover_2025_appliedstats.csv")

# Create data frame for tomato thrips damage for both RS and SEAREC sites
TomatoThripsDamage_raw <- bind_rows(TomatoThripsDamageRS, TomatoThripsDamageSEAREC)

# Change column name 'ground cover' to 'plot_ID'
TomatoThripsDamage_raw <- TomatoThripsDamage_raw %>%
  rename(plot_ID = ground_cover)
  
# Add 'ground_cover' column to combined data
TomatoThripsDamage_raw <- left_join(TomatoThripsDamage_raw, GroundCoverID, by = "plot_ID")

# Subset to remove redundant columns "X", "site.y", and "year"
TomatoThripsDamage <- subset(TomatoThripsDamage_raw, select= -c(X, site.y, year))

# Rename column 'site.x' to 'site'
TomatoThripsDamage <- TomatoThripsDamage %>%
  rename(site = site.x)

```

```{r}
# Tidy temperature data
# List temperature files from local path 
temperature_list <- list.files(path = "C:/Users/mykal/OneDrive - The Pennsylvania State University/Grab Lab - Mykalas_Projects - Documents/Mykalas_Projects/projects/High Tunnel Thrips/analysis/HTT-AppliedStats/data", pattern = "^temp_")

# Create data frame names for temp_list without ".csv" at end
temperature_names <- sub("\\.csv$", "", temperature_list)

for (i in temperature_names) {
# set file path
  filepath <- file.path("C:/Users/mykal/OneDrive - The Pennsylvania State University/Grab Lab - Mykalas_Projects - Documents/Mykalas_Projects/projects/High Tunnel Thrips/analysis/HTT-AppliedStats/data", 
  paste(i, ".csv", sep = ""))

# read each file and name it the file name
  assign(i, 
    read.delim(filepath,
    skip = 19,
    header = TRUE,
    colClasses=c("factor","factor", rep("numeric", 4)),
    sep = ","))

}

## Tidy over multiple data frames
# Create list of temp dataframes
temperature_df_list <- mget(ls(.GlobalEnv, pattern = "^temp_")

temperature_df_list_purrr <- temperature_df_list %>%
  map(~ .x %>% 
    # rename column names
    rename(date = YYYY.MM.DD,
    time = HH.MM.SS,
    temperature = Temperature...,
    humidity = Humidity..RH.) %>%
    # delete some empty columns
    select(!(c(TemperatureStatus, HumidityStatus, X, X.1)))
    )

# update changes to dataframe list in the global environment
list2env(temperature_df_list_purrr, .GlobalEnv)

# Create columns from file name contents
# add column for 'below' or 'above'
# add column for site
# add column for groundcover
# not applied yet
temperature_names_parts <- strsplit(temperature_names, "_")
  site <- temperature_names_parts[2]
  plot_ID <- temperature_names_parts[3]
  sens_placement <- temperature_names_parts[4]

# lubridate on date and time columns



## data corrections with if then statement
# make sure all temp readings are either all C or all F
# fill gaps with averages








```